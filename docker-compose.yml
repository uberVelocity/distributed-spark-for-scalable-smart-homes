version: '3'

networks:
  household-network:
    driver: bridge

volumes:
  cassandra-volume:
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local
  kafka2_data:
    driver: local
  kafka3_data:
    driver: local

services:

# Cassandra infrastructure
  cassandra-cluster:
    container_name: cassandra-cluster
    restart: always
    build: ./cassandra/cassandra_build
    networks:
      - household-network
    volumes:
      - cassandra-volume:/var/lib/cassandra
    expose:
      - 7000
      - 7001
      - 7199
      - 9042
      - 9160

 # Inserts data into cassandra
  predictionconsumer:
    container_name: prediction-consumer
    restart: always
    build: prediction_consumer
    ports:
      - 3005:3005
    networks:
      - household-network

#  Inserts data into cassandra
  db-interface:
    container_name: dbinterface
    restart: always
    build: cassandra/db_interface
    image: ubervelocity/sca_dbinterface:1.0
    ports:
      - 4004:4004
    networks:
      - household-network


  # Zookeeper
  zookeeper:
    container_name: zookeeper
    image: 'bitnami/zookeeper:3'
    ports:
     - '2181:2181'
    volumes:
     - 'zookeeper_data:/bitnami'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - household-network

  # Kafka infrastructure
  kafka:
    image: 'bitnami/kafka:2'
    restart: always
    container_name: kafka_1
    ports:
      - '9091:9091'
      - '29091:29091'
    networks:
      - household-network
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9091,PLAINTEXT_HOST://:29091
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9091,PLAINTEXT_HOST://kafka:29091
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=3
    volumes:
      - 'kafka2_data:/bitnami'
    depends_on:
      - zookeeper
    logging:
      driver: "none"

  kafka2:
    container_name: kafka_2
    restart: always
    image: 'bitnami/kafka:2'
    ports:
      - '9092:9092'
      - '29092:29092'
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,PLAINTEXT_HOST://:29092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka2:9092,PLAINTEXT_HOST://kafka2:29092
    networks:
      - household-network
    volumes:
      - 'kafka_data:/bitnami'
    depends_on:
      - zookeeper
    logging:
      driver: "none"

  kafka3:
    image: 'bitnami/kafka:2'
    restart: always
    container_name: kafka_3
    ports:
      - '9093:9093'
      - '29093:9092'
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9093,PLAINTEXT_HOST://:29093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka3:9093,PLAINTEXT_HOST://kafka3:29093
    networks:
      - household-network
    volumes:
      - 'kafka3_data:/bitnami'
    depends_on:
      - zookeeper
    logging:
      driver: "none"

  kafka_manager:
    container_name: kafka_manager
    image: sheepkiller/kafka-manager
    restart: always
    ports:
      - '9000:9000'
    networks:
      - household-network
    environment:
      - ZK_HOSTS=zookeeper:2181

  # Sensors
  sensor_heater:
    environment:
      - KAFKA='kafka-29091':'kafka2-29092':'kafka3-29093'
    container_name: sensor_heater
    networks:
      - household-network
    build:
      context: .
      dockerfile: sensors/heater_app/Dockerfile
    image: ubervelocity/sca_heater:1.0
    depends_on:
      - zookeeper
      - kafka
      - kafka2
      - kafka3
    logging:
      driver: "none"

#  sensor_lamp:
#    environment:
#      - KAFKA='kafka-29091':'kafka2-29092':'kafka3-29093'
#    container_name: sensor_lamp
#    networks:
#      - household-network
#    build:
#      context: .
#      dockerfile: sensors/lamp_app/Dockerfile
#    image: ubervelocity/sca_lamp:1.0
#    depends_on:
#      - zookeeper
#      - kafka
#      - kafka2
#      - kafka3
#    logging:
#      driver: "none"
#
#  sensor_vacuum:
#    environment:
#      - KAFKA='kafka-29091':'kafka2-29092':'kafka3-29093'
#    container_name: sensor_vacuum
#    networks:
#      - household-network
#    build:
#      context: .
#      dockerfile: sensors/vacuum_app/Dockerfile
#    image: ubervelocity/sca_vacuum:1.0
#
#    depends_on:
#      - zookeeper
#      - kafka
#      - kafka2
#      - kafka3
#    logging:
#      driver: "none"

# Spark infrastructure
  spark-master:
    container_name: spark-master
    networks:
      - household-network
    build: spark/spark_master/
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '7077:7077'

  spark-worker-1:
    container_name: spark_worker_1
    image: bitnami/spark:2.4.5
    networks:
      - household-network
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no

#  spark-worker-2:
#    container_name: spark_worker_2
#    image: bitnami/spark:2.4.5
#    networks:
#      - household-network
#    environment:
#      - SPARK_MODE=worker
#      - SPARK_MASTER_URL=spark://spark-master:7077
#      - SPARK_WORKER_MEMORY=1G
#      - SPARK_WORKER_CORES=1
#      - SPARK_RPC_AUTHENTICATION_ENABLED=no
#      - SPARK_RPC_ENCRYPTION_ENABLED=no
#      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
#      - SPARK_SSL_ENABLED=no

  # Spark nodes used for submitting pyspark applications
  spark-heater:
    build: spark/ml/
    container_name: 'spark-heater'
    environment:
      - MODEL='heater'
      - KAFKA='kafka-29091':'kafka2-29092':'kafka3-29093'
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    networks:
      - household-network

#  spark-lamp:
#    build: spark/ml/
#    container_name: 'spark-lamp'
#    environment:
#      - MODEL='lamps'
#      - KAFKA='kafka-29091':'kafka2-29092':'kafka3-29093'
#      - SPARK_MODE=master
#      - SPARK_RPC_AUTHENTICATION_ENABLED=no
#      - SPARK_RPC_ENCRYPTION_ENABLED=no
#      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
#      - SPARK_SSL_ENABLED=no
#    networks:
#      - household-network
#
#  spark-vacuum:
#    build: spark/ml/
#    container_name: 'spark-vacuum'
#    environment:
#      - MODEL='vacuums'
#      - KAFKA='kafka-29091':'kafka2-29092':'kafka3-29093'
#      - SPARK_MODE=master
#      - SPARK_RPC_AUTHENTICATION_ENABLED=no
#      - SPARK_RPC_ENCRYPTION_ENABLED=no
#      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
#      - SPARK_SSL_ENABLED=no
#    networks:
#      - household-network

#    # Spark node used for submitting pyspark applications
#  spark:
#    build: spark/streaming_worker
#    container_name: 'spark'
#    environment:
#      - SPARK_MODE=master
#      - SPARK_RPC_AUTHENTICATION_ENABLED=no
#      - SPARK_RPC_ENCRYPTION_ENABLED=no
#      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
#      - SPARK_SSL_ENABLED=no
#    ports:
#      - '8080:8080'
#    networks:
#      - household-network

  node-streaming:
    container_name: node_streaming
    restart: always
    build: spark/node_streaming_worker
    ports:
      - 4005:4005
    networks:
      - household-network
      
  # Frontend
  frontend:
    container_name: frontend
    restart: always
    build: frontend/household-view
    ports:
      - '80:80'
    networks:
      - household-network
    logging:
      driver: "none"
